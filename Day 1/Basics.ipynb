{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHWv7DrK5bvX"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJUVD0nK5TQf"
   },
   "source": [
    "**Day 1: Basics of Pytorch**\n",
    "\n",
    "**Introduction to Tensors in PyTorch**\n",
    "\n",
    "What Are Tensors?\n",
    "Tensors are the fundamental building blocks of PyTorch. They are multi-dimensional arrays similar to NumPy arrays but with additional capabilities, such as running on GPUs for faster computation.\n",
    "\n",
    "A tensor can represent:\n",
    "\n",
    "Scalar (0D Tensor) → A single number (e.g., 3.14)\n",
    "\n",
    "Vector (1D Tensor) → A 1D array (e.g., [1, 2, 3])\n",
    "\n",
    "Matrix (2D Tensor) → A 2D array (e.g., [[1, 2], [3, 4]])\n",
    "\n",
    "Higher-Dimensional Tensors (3D, 4D, etc.) → Used for deep learning, images, videos, etc.\n",
    "\n",
    "Why Use Tensors Instead of NumPy?\n",
    "\n",
    "**GPU Support** – PyTorch tensors can run on GPUs, making them much faster than NumPy for large computations.\n",
    "\n",
    "**Automatic Differentiation** – PyTorch tensors work with autograd, which is essential for deep learning.\n",
    "\n",
    "**Deep Learning** – PyTorch models use tensors for training and inference.\n",
    "\n",
    "Creating Tensors in PyTorch\n",
    "\n",
    "Let's see how to create different types of tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YT_nqv3t5Y8w",
    "outputId": "d8d95358-19bc-4216-b0d9-ff7cf709127c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.5209, 0.8132, 0.4436],\n",
      "        [0.4182, 0.6369, 0.7515]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a simple tensor\n",
    "x = torch.tensor([1,2,3])\n",
    "print(x)\n",
    "\n",
    "# Tensor filled with zeros, If you have used numpy before most of this functions might seem familiar\n",
    "zeros = torch.zeros(3,3)\n",
    "print(zeros)\n",
    "\n",
    "# Tensor filled with ones\n",
    "ones = torch.ones(2,2)\n",
    "print(ones)\n",
    "\n",
    "# Random tensor\n",
    "rand_tensor = torch.rand(2,3)\n",
    "print(rand_tensor)\n",
    "\n",
    "# Identity matric\n",
    "eye = torch.eye(3)\n",
    "print(eye)\n",
    "\n",
    "arange_tensor = torch.arange(0,10,2)\n",
    "print(arange_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oxq1-7I78uzv"
   },
   "source": [
    "**Checking Tensor Properties**\n",
    "\n",
    "Every tensor has important properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SzBG6vnf8g2r",
    "outputId": "a61eb927-9a43-4bfc-d2cb-37aeb38ca000"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([3, 4])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, 4)\n",
    "print(\"Shape:\", x.shape)  # Shape of tensor\n",
    "print(\"Data type:\", x.dtype)  # Data type\n",
    "print(\"Device:\", x.device)  # Where the tensor is stored (CPU/GPU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHPK7eH89FTn"
   },
   "source": [
    "**Basic Tensor Operations**\n",
    "\n",
    "You can perform various operations on tensors just like in NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-kQzirA8-wv",
    "outputId": "3b64fdd9-f6f4-40a8-c0f3-038a46e0f48c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n",
      "tensor([ 4, 10, 18])\n",
      "tensor([[0.4543, 0.7116],\n",
      "        [0.2909, 0.4511]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Element-wise addition\n",
    "print(a + b)\n",
    "\n",
    "# Element-wise multiplication\n",
    "print(a * b)\n",
    "\n",
    "# Matrix multiplication\n",
    "A = torch.rand(2, 3)\n",
    "B = torch.rand(3, 2)\n",
    "C = torch.mm(A, B)  # Matrix multiplication\n",
    "print(C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRZrh11-9ee3"
   },
   "source": [
    "**Broadcasting in PyTorch**\n",
    "\n",
    "Broadcasting is a technique that automatically expands the dimensions of tensors so they can be used together in arithmetic operations without explicit reshaping\n",
    "\n",
    "This is similar to NumPy broadcasting, allowing operations on tensors of different shapes without unnecessary memory duplication.\n",
    "\n",
    "**Example 1: Scalar with a Tensor**\n",
    "\n",
    "A scalar (single number) automatically broadcasts across all elements of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KKUBdP6c9PA4",
    "outputId": "c1bfbf67-56f2-4db3-aaa0-02980c91486c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])  # Shape: (3,)\n",
    "y = 2  # Scalar\n",
    "\n",
    "print(x + y)  # [3, 4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuuoEbXH-BCV"
   },
   "source": [
    "**Example 2: Different Shapes (1D & 2D Tensor)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bh98HkWX991P",
    "outputId": "bd47c435-56fa-49f2-9521-120087e889d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3], [4, 5, 6]])  # Shape: (2, 3)\n",
    "b = torch.tensor([10, 20, 30])  # Shape: (3,)\n",
    "\n",
    "print(a + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnFs-Laf-Mc0"
   },
   "source": [
    "**Example 3: Expanding a Column Vector**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmP0NGMj-Hut",
    "outputId": "0c75d68e-a504-4f47-9905-a027e1bd6657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 21, 31],\n",
      "        [12, 22, 32],\n",
      "        [13, 23, 33]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1], [2], [3]])  # Shape: (3, 1)\n",
    "b = torch.tensor([10, 20, 30])  # Shape: (3,)\n",
    "\n",
    "print(a + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLkPTe4G-nWC"
   },
   "source": [
    "**When Broadcasting Fails**\n",
    "\n",
    "If PyTorch can’t match dimensions, it throws an error:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "26b0lUK0-XUo",
    "outputId": "a1e0b0b9-a7d9-4bd1-b130-a6ab2acb5430"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2ea85aaa68fa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# RuntimeError: The size of tensor b (4) must match tensor a (3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3)\n",
    "b = torch.rand(2, 4)\n",
    "\n",
    "print(a + b) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEFO83ap-5UN"
   },
   "source": [
    "**How to Expand a Tensor Manually?**\n",
    "\n",
    "If broadcasting fails, you can explicitly reshape a tensor using unsqueeze() or expand().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xATrI1Xl-wO1",
    "outputId": "91e506bf-bf89-417c-8e56-b19501a08eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])  # Shape: (3,)\n",
    "b = a.unsqueeze(1)  # Shape: (3,1)\n",
    "print(b)\n",
    "print(b.expand(3, 3))  # Expands to (3,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfTA79zN_WMZ"
   },
   "source": [
    "**Moving Tensors to GPU**\n",
    "\n",
    "If you have a GPU, you can move tensors to it for faster computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHyCz2dt_ILV",
    "outputId": "c4001969-ae0e-493a-e9f2-4b7052475f1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor on: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tensor = torch.rand(3, 3).to(device)\n",
    "print(\"Tensor on:\", tensor.device)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
